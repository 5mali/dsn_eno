{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from datetime import datetime\n",
    "tic = datetime.now()\n",
    "\n",
    "import os\n",
    "from os.path import dirname, abspath, join\n",
    "from os import getcwd\n",
    "import sys\n",
    "\n",
    "# THIS_DIR = getcwd()\n",
    "# CLASS_DIR = abspath(join(THIS_DIR, 'dsnclasses'))  #abspath(join(THIS_DIR, '../../..', 'dsnclasses'))\n",
    "# sys.path.append(CLASS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import torch\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 161\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENO(object):\n",
    "    \n",
    "    #no. of forecast types is 6 ranging from 0 to 5\n",
    "  \n",
    "    def __init__(self, location='tokyo', year=2010, shuffle=False, day_balance=False):\n",
    "        self.location = location\n",
    "        self.year = year\n",
    "        self.day = None\n",
    "        self.hr = None\n",
    "        \n",
    "        self.shuffle = shuffle\n",
    "        self.day_balance = day_balance\n",
    "\n",
    "        self.TIME_STEPS = None #no. of time steps in one episode\n",
    "        self.NO_OF_DAYS = None #no. of days in one year\n",
    "        \n",
    "        self.NO_OF_DAYTYPE = 10 #no. of daytypes\n",
    "        self.daycounter = 0 #to count number of days that have been passed\n",
    "        \n",
    "        self.sradiation = None #matrix with GSR for the entire year\n",
    "        self.senergy = None #matrix with harvested energy data for the entire year\n",
    "        self.fforecast = None #array with forecast values for each day\n",
    "        \n",
    "\n",
    "        self.henergy = None #harvested energy variable\n",
    "        self.fcast = None #forecast variable\n",
    "        self.sorted_days = [] #days sorted according to day type\n",
    "        \n",
    "        self.SMAX = 1000 # 1 Watt Solar Panel\n",
    "\n",
    "    \n",
    "    #function to get the solar data for the given location and year and prep it\n",
    "    def get_data(self):\n",
    "        #solar_data/CSV files contain the values of GSR (Global Solar Radiation in MegaJoules per meters squared per hour)\n",
    "        #weather_data/CSV files contain the weather summary from 06:00 to 18:00 and 18:00 to 06:00+1\n",
    "        location = self.location\n",
    "        year = self.year\n",
    "\n",
    "        THIS_DIR = getcwd()\n",
    "        SDATA_DIR = abspath(join(THIS_DIR, 'solar_data'))  #abspath(join(THIS_DIR, '../../..', 'data'))\n",
    "        \n",
    "        sfile = SDATA_DIR + '/' + location +'/' + str(year) + '.csv'\n",
    "        \n",
    "        #skiprows=4 to remove unnecessary title texts\n",
    "        #usecols=4 to read only the Global Solar Radiation (GSR) values\n",
    "        solar_radiation = pd.read_csv(sfile, skiprows=4, encoding='shift_jisx0213', usecols=[4])\n",
    "      \n",
    "        #convert dataframe to numpy array\n",
    "        solar_radiation = solar_radiation.values\n",
    "\n",
    "        #convert missing data in CSV files to zero\n",
    "        solar_radiation[np.isnan(solar_radiation)] = 0\n",
    "\n",
    "        #reshape solar_radiation into no_of_daysx24 array\n",
    "        solar_radiation = solar_radiation.reshape(-1,24)\n",
    "\n",
    "        if(self.shuffle): #if class instatiation calls for shuffling the day order. Required when learning\n",
    "            np.random.shuffle(solar_radiation) \n",
    "        self.sradiation = solar_radiation\n",
    "        \n",
    "        #GSR values (in MJ/sq.mts per hour) need to be expressed in mW\n",
    "        # Conversion is accomplished by \n",
    "        # solar_energy = GSR(in MJ/m2/hr) * 1e6 * size of solar cell * efficiency of solar cell /(60x60) *1000 (to express in mW)\n",
    "        # the factor of 2 in the end is assuming two solar cells\n",
    "        self.senergy = 2*self.sradiation * 1e6 * (55e-3 * 70e-3) * 0.15 * 1000/(60*60)\n",
    "\n",
    "        return 0\n",
    "    \n",
    "    #function to map total day radiation into type of day ranging from 0 to 5\n",
    "    #the classification into day types is quite arbitrary. There is no solid logic behind this type of classification.\n",
    "    \n",
    "    def get_day_state(self,tot_day_radiation):\n",
    "        bin_edges = np.array([0, 3.5, 6.5, 9.0, 12.5, 15.5, 18.5, 22.0, 25, 28])\n",
    "        for k in np.arange(1,bin_edges.size):\n",
    "            if (bin_edges[k-1] < tot_day_radiation <= bin_edges[k]):\n",
    "                day_state = k -1\n",
    "            else:\n",
    "                day_state = bin_edges.size - 1\n",
    "        return int(day_state)\n",
    "    \n",
    "    def get_forecast(self):\n",
    "        #create a perfect forecaster.\n",
    "        tot_day_radiation = np.sum(self.sradiation, axis=1) #contains total solar radiation for each day\n",
    "        get_day_state = np.vectorize(self.get_day_state)\n",
    "        self.fforecast = get_day_state(tot_day_radiation)\n",
    "        \n",
    "        #sort days depending on the type of day and shuffle them; maybe required when learning\n",
    "        for fcast in range(0,6):\n",
    "            fcast_days = ([i for i,x in enumerate(self.fforecast) if x == fcast])\n",
    "            np.random.shuffle(fcast_days)\n",
    "            self.sorted_days.append(fcast_days)\n",
    "        return 0\n",
    "    \n",
    "    def reset(self,day=0): #it is possible to reset to the beginning of a certain day\n",
    "        \n",
    "        self.get_data() #first get data for the given year\n",
    "        self.get_forecast() #calculate the forecast\n",
    "        \n",
    "        self.TIME_STEPS = self.senergy.shape[1]\n",
    "        self.NO_OF_DAYS = self.senergy.shape[0]\n",
    "        \n",
    "        self.day = day\n",
    "        self.hr = 0\n",
    "        \n",
    "        self.henergy = self.senergy[self.day][self.hr]\n",
    "        self.fcast = self.fforecast[self.day]\n",
    "        \n",
    "        end_of_day = False\n",
    "        end_of_year = False\n",
    "        return [self.henergy, self.fcast, end_of_day, end_of_year]\n",
    "\n",
    "    \n",
    "    def step(self):\n",
    "        end_of_day = False\n",
    "        end_of_year = False\n",
    "        if not(self.day_balance): #if daytype balance is not required\n",
    "            if(self.hr < self.TIME_STEPS - 1):\n",
    "                self.hr += 1\n",
    "                self.henergy = self.senergy[self.day][self.hr] \n",
    "                self.fcast = self.fforecast[self.day]\n",
    "            else:\n",
    "                if(self.day < self.NO_OF_DAYS -1):\n",
    "                    end_of_day = True\n",
    "                    self.hr = 0\n",
    "                    self.day += 1\n",
    "                    self.henergy = self.senergy[self.day][self.hr] \n",
    "                    self.fcast = self.fforecast[self.day]\n",
    "                else:\n",
    "                    end_of_day = True\n",
    "                    end_of_year = True\n",
    "                    \n",
    "        else: #when training, we want all daytypes to be equally represented for robust policy\n",
    "              #obviously, the days are going to be in random order\n",
    "            if(self.hr < self.TIME_STEPS - 1):\n",
    "                self.hr += 1\n",
    "                self.henergy = self.senergy[self.day][self.hr]\n",
    "                self.fcast = self.fforecast[self.day]\n",
    "            else:\n",
    "                if(self.daycounter < self.NO_OF_DAYS -1):\n",
    "                    end_of_day = True\n",
    "                    self.daycounter += 1\n",
    "                    self.hr = 0\n",
    "                    daytype = random.choice(np.arange(0,self.NO_OF_DAYTYPE)) #choose random daytype\n",
    "                    self.day = np.random.choice(self.sorted_days[daytype]) #choose random day from that daytype\n",
    "                    self.henergy = self.senergy[self.day][self.hr] \n",
    "                    self.fcast = self.fforecast[self.day]\n",
    "                else: \n",
    "                    end_of_day = True\n",
    "                    end_of_year = True\n",
    "                    self.daycounter = 0\n",
    "        \n",
    "        \n",
    "        return [self.henergy, self.fcast, end_of_day, end_of_year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAPM (object):\n",
    "    def __init__(self,location='tokyo', year=2010, shuffle=False, trainmode=False):\n",
    "\n",
    "        #all energy values i.e. BMIN, BMAX, BOPT, HMAX are in mWhr. Assuming one timestep is one hour\n",
    "        \n",
    "        self.BMIN = 0.0                #Minimum battery level that is tolerated. Maybe non-zero also\n",
    "        self.BMAX = 9250.0            #Max Battery Level. May not necessarily be equal to total batter capacity [3.6V x 2500mAh]\n",
    "        self.BOPT = 0.5 * self.BMAX    #Optimal Battery Level. Assuming 50% of battery is the optimum\n",
    "        \n",
    "        self.HMIN = 0      #Minimum energy that can be harvested by the solar panel.\n",
    "        self.HMAX = None   #Maximum energy that can be harvested by the solar panel. [500mW]\n",
    "        \n",
    "        self.DMAX = 500      #Maximum energy that can be consumed by the node in one time step. [~ 3.6V x 135mA]\n",
    "        self.N_ACTIONS = 10  #No. of different duty cycles possible\n",
    "        self.DMIN = self.DMAX/self.N_ACTIONS #Minimum energy that can be consumed by the node in one time step. [~ 3.6V x 15mA]\n",
    "        \n",
    "        self.binit = None     #battery at the beginning of day\n",
    "        self.btrack = []      #track the mean battery level for each day\n",
    "        self.atrack = [0]      #track the duty cycles for each day\n",
    "        self.batt = None      #battery variable\n",
    "        self.enp = None       #enp at end of hr\n",
    "        self.henergy = None   #harvested energy variable\n",
    "        self.fcast = None     #forecast variable\n",
    "        \n",
    "        self.MUBATT = 0.6\n",
    "        self.SDBATT = 0.02\n",
    "        \n",
    "        self.MUHENERGY = 0.5\n",
    "        self.SDHENERGY = 0.2\n",
    "        \n",
    "        self.MUENP = 0\n",
    "        self.SDENP = 0.02\n",
    "        \n",
    "        self.location = location\n",
    "        self.year = year\n",
    "        self.shuffle = shuffle\n",
    "        self.trainmode = trainmode\n",
    "        self.eno = None#ENO(self.location, self.year, shuffle=shuffle, day_balance=trainmode) #if trainmode is enable, then days are automatically balanced according to daytype i.e. day_balance= True\n",
    "        \n",
    "        self.day_violation_flag = False\n",
    "        self.violation_flag = False\n",
    "        self.violation_counter = 0\n",
    "\n",
    "        self.NO_OF_DAYTYPE = 10 #no. of daytypes\n",
    " \n",
    "    def reset(self,day=0,batt=-1):\n",
    "        henergy, fcast, day_end, year_end = self.eno.reset(day) #reset the eno environment\n",
    "        self.violation_flag = False\n",
    "        self.violation_counter = 0\n",
    "        if(batt == -1):\n",
    "            self.batt = self.BOPT\n",
    "        else:\n",
    "            self.batt = batt\n",
    "            \n",
    "        self.batt = np.clip(self.batt, self.BMIN, self.BMAX)\n",
    "        self.binit = self.batt\n",
    "        self.btrack = np.append(self.btrack, self.batt) #track battery levels\n",
    "\n",
    "#         self.enp = self.BOPT - self.batt\n",
    "        self.enp = self.binit - self.batt #enp is calculated\n",
    "        self.henergy = np.clip(henergy, self.HMIN, self.HMAX) #clip henergy within HMIN and HMAX\n",
    "        self.fcast = fcast\n",
    "        \n",
    "        norm_batt = self.batt/self.BMAX\n",
    "        norm_enp = self.enp/(self.BMAX/2)\n",
    "        norm_henergy = self.henergy/self.HMAX\n",
    "        norm_fcast = self.fcast/(self.NO_OF_DAYTYPE-1)\n",
    "\n",
    "        c_state = [norm_batt, norm_enp, norm_henergy, norm_fcast] #continuous states\n",
    "        reward = 0\n",
    "        \n",
    "        return [c_state, reward, day_end, year_end]\n",
    "    \n",
    "    def getstate(self): #query the present state of the system\n",
    "        norm_batt = self.batt/self.BMAX - self.MUBATT\n",
    "        norm_enp = self.enp/(self.BMAX/2)\n",
    "        norm_henergy = self.henergy/self.HMAX\n",
    "        norm_fcast = self.fcast/(self.NO_OF_DAYTYPE-1)        \n",
    "        c_state = [norm_batt, norm_enp, norm_henergy] #continuous states\n",
    "\n",
    "        return c_state\n",
    "    \n",
    "#     def rewardfn(self):\n",
    "#         R_PARAM = 20000 #chosen empirically for best results\n",
    "#         mu = 0\n",
    "#         sig = 0.07*R_PARAM #knee curve starts at approx. 2000mWhr of deviation\n",
    "#         norm_reward = 3*(np.exp(-np.power((self.enp - mu)/sig, 2.)/2) / np.exp(-np.power((0 - mu)/sig, 2.)/2))-1\n",
    "\n",
    "        \n",
    "# #         if(np.abs(self.enp) <= 0.12*R_PARAM):\n",
    "# #             norm_reward = 2*(np.exp(-np.power((self.enp - mu)/sig, 2.)/2) / np.exp(-np.power((0 - mu)/sig, 2.)/2))\n",
    "# #         else:\n",
    "# #             norm_reward = -0.25 - 10*np.abs(self.enp/R_PARAM)\n",
    "#         if(self.day_violation_flag):\n",
    "#             norm_reward -= 3\n",
    "            \n",
    "#         return (norm_reward)\n",
    "        \n",
    "    \n",
    "    #reward function\n",
    "    def rewardfn(self):\n",
    "        \n",
    "        #FIRST REWARD AS A FUNCTION OF DRIFT OF BMEAN FROM BOPT i.e. in terms of BDEV = |BMEAN-BOPT|/BMAX\n",
    "        bmean = np.mean(self.btrack)\n",
    "        bdev = np.abs(self.BOPT - bmean)/self.BMAX\n",
    "        # based on the sigmoid function\n",
    "        # bdev ranges from bdev = (0,0.5) of BMAX\n",
    "        p1_sharpness = 10\n",
    "        n1_sharpness = 20\n",
    "        shift1 = 0.5\n",
    "        # r1(x) = 0.5 when x = 0.25. \n",
    "        # Therefore, shift = 0.5 to make sure that (2*x-shift) evaluates to zero at x = 0.25\n",
    "\n",
    "        if(bdev<=0.25): \n",
    "            r1 = 2*(1-(1 / (1 + np.exp(-p1_sharpness*(2*bdev-shift1)))))-1\n",
    "        else: \n",
    "            r1 = 2*(1-(1 / (1 + np.exp(-n1_sharpness*(2*bdev-shift1)))))-1\n",
    "        # r1 ranges from -1 to 1\n",
    "            \n",
    "        #SECOND REWARD AS A FUNCTION OF ENP AS LONG AS BMAX/4 <= batt <= 3*BMAX/4 i.e. bdev <= 0.25\n",
    "        if(bdev <=0.25):\n",
    "            # enp ranges from enp = (0,3) of DMAX\n",
    "            p2_sharpness = 2\n",
    "            n2_sharpness = 2\n",
    "            shift2 = 6    \n",
    "            # r1(x) = 0.5 when x = 2. \n",
    "            # Therefore, shift = 6 to make sure that (3*x-shift) evaluates to zero at x = 2\n",
    "#             print('Day energy', np.sum(self.eno.senergy[self.eno.day]))\n",
    "#             print('Node energy', np.sum(self.atrack)*self.DMAX/self.N_ACTIONS)\n",
    "#             x = np.abs(np.sum(self.eno.senergy[self.eno.day])-np.sum(self.atrack)*self.DMAX/self.N_ACTIONS )/self.DMAX\n",
    "            x = np.abs(self.enp/self.DMAX)\n",
    "            if(x<=2): \n",
    "                r2 = (1 / (1 + np.exp(p2_sharpness*(3*x-shift2))))\n",
    "            else: \n",
    "                r2 = (1 / (1 + np.exp(n2_sharpness*(3*x-shift2))))\n",
    "        else:\n",
    "            r2 = 0 # if mean battery lies outside bdev limits, then enp reward is not considered.\n",
    "        # r2 ranges from 0 to 1\n",
    "\n",
    "        violation_penalty = 0    \n",
    "        #REWARD AS A FUNCTION OF BATTERY VIOLATIONS\n",
    "        if(self.enp < 0):\n",
    "            violation_penalty = 4\n",
    "                \n",
    "        if(self.day_violation_flag):\n",
    "            violation_penalty += 3\n",
    "        else:\n",
    "            violation_penalty = 0 #penalty for violating battery limits anytime during the day\n",
    "        \n",
    "#         print(\"Reward \", (r1 + r2 - violation_penalty), '\\n')\n",
    "        return (r1*(2**r2) - violation_penalty)\n",
    "    \n",
    "    def step(self, action):\n",
    "        day_end = False\n",
    "        year_end = False\n",
    "        self.violation_flag = False\n",
    "        var = np.abs((1-(np.mean(self.atrack) - action)/9))\n",
    "        reward = 4*( 0.5 - np.abs(  (np.mean(self.atrack) - action)/9 )  ) #reward penalizing high duty cycle variance\n",
    "\n",
    "#         reward = 1/(1+np.exp(20*(var-0.3)))#reward penalizing high duty cycle variance\n",
    "       \n",
    "        action = np.clip(action, 0, self.N_ACTIONS-1) #action values range from (0 to N_ACTIONS-1)\n",
    "        self.atrack = np.append(self.atrack, action+1) #track duty cycles\n",
    "        e_consumed = (action+1)*self.DMAX/self.N_ACTIONS   #energy consumed by the node\n",
    "        \n",
    "        self.batt += (self.henergy - e_consumed)\n",
    "        if(self.batt < 0.02*self.BMAX or self.batt > 0.98*self.BMAX ):\n",
    "            self.violation_flag = True #penalty for violating battery limits everytime it happens\n",
    "            reward -= 2\n",
    "        if(self.batt < 0.02*self.BMAX):\n",
    "            reward -= 2\n",
    "            \n",
    "        if(self.violation_flag):\n",
    "            if(self.day_violation_flag == False): #penalty for violating battery limits anytime during the day - triggers once everyday\n",
    "                self.violation_counter += 1\n",
    "                self.day_violation_flag = True\n",
    "            \n",
    "        self.batt = np.clip(self.batt, self.BMIN, self.BMAX) #clip battery values within permitted level\n",
    "        self.btrack = np.append(self.btrack, self.batt) #track battery levels\n",
    "\n",
    "#         self.enp = self.BOPT - self.batt \n",
    "        self.enp = self.binit - self.atrack.sum()*self.DMAX/self.N_ACTIONS\n",
    "        \n",
    "        #proceed to the next time step\n",
    "        self.henergy, self.fcast, day_end, year_end = self.eno.step()\n",
    "        self.henergy = np.clip(self.henergy, self.HMIN, self.HMAX) #clip henergy within HMIN and HMAX\n",
    "                \n",
    "        if(day_end): #if eno object flags that the day has ended then give reward\n",
    "            reward += self.rewardfn()\n",
    "             \n",
    "            if (self.trainmode): #reset battery to optimal level if limits are exceeded when training\n",
    "#                 self.batt = np.random.uniform(self.DMAX*self.eno.TIME_STEPS/self.BMAX,0.8)*self.BMAX\n",
    "#                 if (self.violation_flag):\n",
    "                if np.random.uniform() < HELP : #occasionaly reset the battery\n",
    "                    self.batt = self.BOPT  \n",
    "            \n",
    "            self.day_violation_flag = False\n",
    "            self.binit = self.batt #this will be the new initial battery level for next day\n",
    "            self.btrack = [] #clear battery tracker\n",
    "            self.atrack = [0] #clear duty cycle tracker\n",
    "            \n",
    "                    \n",
    "                \n",
    "        norm_batt = self.batt/self.BMAX\n",
    "        norm_enp = self.enp/(self.BMAX/2)\n",
    "        norm_henergy = self.henergy/self.HMAX\n",
    "        norm_fcast = self.fcast/(self.NO_OF_DAYTYPE-1)\n",
    "\n",
    "        c_state = [norm_batt, norm_enp, norm_henergy, norm_fcast] #continuous states\n",
    "        return [c_state, reward, day_end, year_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.00001          # learning rate\n",
    "EPSILON = 0.9               # greedy policy\n",
    "GAMMA = 0.9                 # reward discount\n",
    "LAMBDA = 0.9                # parameter decay\n",
    "TARGET_REPLACE_ITER = 24*7*4*6    # target update frequency (every two months)\n",
    "MEMORY_CAPACITY     = 24*7*4*12*2      # store upto six month worth of memory   \n",
    "\n",
    "N_ACTIONS = 10 #no. of duty cycles (0,1,2,3,4)\n",
    "N_STATES = 4 #number of state space parameter [batt, enp, henergy, fcast]\n",
    "\n",
    "HIDDEN_LAYER = 50\n",
    "NO_OF_ITERATIONS = 80\n",
    "GPU = False\n",
    "HELP = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "#Class definitions for NN model and learning algorithm\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(N_STATES, HIDDEN_LAYER)\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight)\n",
    "        \n",
    "        self.fc2 = nn.Linear(HIDDEN_LAYER, HIDDEN_LAYER)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        \n",
    "        self.fc3 = nn.Linear(HIDDEN_LAYER, HIDDEN_LAYER)\n",
    "        nn.init.kaiming_uniform_(self.fc3.weight)\n",
    "\n",
    "        self.out = nn.Linear(HIDDEN_LAYER, N_ACTIONS)\n",
    "        nn.init.xavier_uniform_(self.out.weight) \n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        actions_value = self.out(x)\n",
    "        return actions_value\n",
    "    \n",
    "class DQN(object):\n",
    "    def __init__(self):\n",
    "        if(GPU): \n",
    "            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "        self.eval_net, self.target_net = Net(), Net()\n",
    "        self.eval_net.to(device)\n",
    "        self.target_net.to(device)\n",
    "        self.device = device\n",
    "#         print(\"Neural net\")\n",
    "#         print(self.eval_net)\n",
    "        self.learn_step_counter = 0                                     # for target updating\n",
    "        self.memory_counter = 0                                         # for storing memory\n",
    "        self.memory = np.zeros((MEMORY_CAPACITY, N_STATES * 2 + 2))     # initialize memory [mem: ([s], a, r, [s_]) ]\n",
    "        self.optimizer = torch.optim.Adam(self.eval_net.parameters(), lr=LR, weight_decay=1e-3)\n",
    "        self.loss_func = nn.MSELoss()\n",
    "        self.nettoggle = False\n",
    "\n",
    "    def choose_action(self, x):\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)\n",
    "        x = x.to(self.device)\n",
    "\n",
    "        # input only one sample\n",
    "        if np.random.uniform() < EPSILON:   # greedy\n",
    "            actions_value = self.eval_net.forward(x)\n",
    "            actions_value = actions_value.to(torch.device(\"cpu\"))\n",
    "            action = torch.max(actions_value, 1)[1].data.numpy()\n",
    "            action = action[0] # return the argmax index\n",
    "        else:   # random\n",
    "            action = np.random.randint(0, N_ACTIONS)\n",
    "            action = action\n",
    "        return action\n",
    "    \n",
    "    def choose_greedy_action(self, x):\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)\n",
    "        x = x.to(self.device)\n",
    "\n",
    "        # input only one sample\n",
    "        if True:   # greedy\n",
    "            actions_value = self.eval_net.forward(x)\n",
    "            actions_value = actions_value.to(torch.device(\"cpu\"))\n",
    "            action = torch.max(actions_value, 1)[1].data.numpy()\n",
    "            action = action[0] # return the argmax index\n",
    "        return action\n",
    "\n",
    "    def store_transition(self, s, a, r, s_):\n",
    "        transition = np.hstack((s, [a, r], s_))\n",
    "        # replace the old memory with new memory\n",
    "        index = self.memory_counter % MEMORY_CAPACITY\n",
    "        self.memory[index, :] = transition\n",
    "        self.memory_counter += 1\n",
    "    \n",
    "    def store_day_transition(self, transition_rec):\n",
    "        data = transition_rec\n",
    "        index = self.memory_counter % MEMORY_CAPACITY\n",
    "        self.memory= np.insert(self.memory, index, data,0)\n",
    "        self.memory_counter += transition_rec.shape[0]\n",
    "\n",
    "    def learn(self):\n",
    "        # target parameter update\n",
    "        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:\n",
    "            self.target_net.load_state_dict(self.eval_net.state_dict())\n",
    "            self.nettoggle = not self.nettoggle\n",
    "        self.learn_step_counter += 1\n",
    "\n",
    "        # sample batch transitions\n",
    "        sample_index = np.random.choice(MEMORY_CAPACITY, BATCH_SIZE)\n",
    "        b_memory = self.memory[sample_index, :]\n",
    "        b_s = torch.FloatTensor(b_memory[:, :N_STATES])\n",
    "        b_a = torch.LongTensor(b_memory[:, N_STATES:N_STATES+1].astype(int))\n",
    "        b_r = torch.FloatTensor(b_memory[:, N_STATES+1:N_STATES+2])\n",
    "        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])\n",
    "        \n",
    "        b_s = b_s.to(self.device)\n",
    "        b_a = b_a.to(self.device)\n",
    "        b_r = b_r.to(self.device)\n",
    "        b_s_ = b_s_.to(self.device)\n",
    "\n",
    "        # q_eval w.r.t the action in experience\n",
    "        q_eval = self.eval_net(b_s).gather(1, b_a)  # shape (batch, 1)\n",
    "        q_next = self.target_net(b_s_).detach()     # detach from graph, don't backpropagate\n",
    "        q_target = b_r + GAMMA * q_next.max(1)[0].view(BATCH_SIZE, 1)   # shape (batch, 1)\n",
    "        loss = self.loss_func(q_eval, q_target)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdize(s):\n",
    "    MU_BATT = 0.5\n",
    "    SD_BATT = 0.15\n",
    "    \n",
    "    MU_ENP = 0\n",
    "    SD_ENP = 0.15\n",
    "    \n",
    "    MU_HENERGY = 0.35\n",
    "    SD_HENERGY = 0.25\n",
    "    \n",
    "    MU_FCAST = 0.42\n",
    "    SD_FCAST = 0.27\n",
    "    \n",
    "    norm_batt, norm_enp, norm_henergy, norm_fcast = s\n",
    "    \n",
    "    std_batt = (norm_batt - MU_BATT)/SD_BATT\n",
    "    std_enp = (norm_enp - MU_ENP)/SD_ENP\n",
    "    std_henergy = (norm_henergy - MU_HENERGY)/SD_HENERGY\n",
    "    std_fcast = (norm_fcast - MU_FCAST)/SD_FCAST\n",
    "\n",
    "\n",
    "    return [std_batt, std_enp, std_henergy, std_fcast]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING IN PROGRESS\n",
      "\n",
      "Device:  cpu\n",
      "\n",
      "Iteration 0:  MINAMIDAITO, 2003 \n",
      "EPSILON = 0.5\n",
      "Average Reward \t\t= -9.146\n",
      "Violation Counter \t= 351\n",
      "\n",
      "Iteration 1:  MINAMIDAITO, 2002 \n",
      "EPSILON = 0.58\n",
      "Average Reward \t\t= -9.285\n",
      "Violation Counter \t= 361\n",
      "\n",
      "Iteration 2:  TOKYO, 2009 \n",
      "EPSILON = 0.64\n",
      "Average Reward \t\t= -5.250\n",
      "Violation Counter \t= 245\n",
      "\n",
      "Iteration 3:  WAKKANAI, 2000 \n",
      "EPSILON = 0.69\n",
      "Average Reward \t\t= -7.615\n",
      "Violation Counter \t= 305\n",
      "\n",
      "Iteration 4:  MINAMIDAITO, 2007 \n",
      "EPSILON = 0.72\n",
      "Average Reward \t\t= -4.960\n",
      "Violation Counter \t= 282\n",
      "\n",
      "Iteration 5:  WAKKANAI, 2000 \n",
      "EPSILON = 0.75\n",
      "Average Reward \t\t= -6.816\n",
      "Violation Counter \t= 287\n",
      "\n",
      "Iteration 6:  WAKKANAI, 2000 \n",
      "EPSILON = 0.77\n",
      "Average Reward \t\t= -5.863\n",
      "Violation Counter \t= 258\n",
      "\n",
      "Iteration 7:  WAKKANAI, 2009 \n",
      "EPSILON = 0.79\n",
      "Average Reward \t\t= -4.109\n",
      "Violation Counter \t= 204\n",
      "\n",
      "Iteration 8:  TOKYO, 2009 \n",
      "EPSILON = 0.81\n",
      "Average Reward \t\t= -1.516\n",
      "Violation Counter \t= 127\n",
      "\n",
      "Iteration 9:  WAKKANAI, 2000 \n",
      "EPSILON = 0.82\n",
      "Average Reward \t\t= -3.540\n",
      "Violation Counter \t= 202\n",
      "\n",
      "Iteration 10:  TOKYO, 2004 \n",
      "EPSILON = 0.83\n",
      "Average Reward \t\t= -0.735\n",
      "Violation Counter \t= 127\n",
      "\n",
      "Iteration 11:  MINAMIDAITO, 2004 \n",
      "EPSILON = 0.84\n",
      "Average Reward \t\t= -0.074\n",
      "Violation Counter \t= 127\n",
      "\n",
      "Iteration 12:  MINAMIDAITO, 2006 \n",
      "EPSILON = 0.85\n",
      "Average Reward \t\t= -0.236\n",
      "Violation Counter \t= 142\n",
      "\n",
      "Iteration 13:  WAKKANAI, 2003 \n",
      "EPSILON = 0.86\n",
      "Average Reward \t\t= -1.718\n",
      "Violation Counter \t= 114\n",
      "\n",
      "Iteration 14:  MINAMIDAITO, 2005 \n",
      "EPSILON = 0.87\n",
      "Average Reward \t\t= -0.191\n",
      "Violation Counter \t= 133\n",
      "\n",
      "Iteration 15:  MINAMIDAITO, 2007 \n",
      "EPSILON = 0.88\n",
      "Average Reward \t\t= -0.019\n",
      "Violation Counter \t= 121\n",
      "\n",
      "Iteration 16:  MINAMIDAITO, 2004 \n",
      "EPSILON = 0.88\n",
      "Average Reward \t\t= 0.008\n",
      "Violation Counter \t= 114\n",
      "\n",
      "Iteration 17:  WAKKANAI, 2002 \n",
      "EPSILON = 0.89\n",
      "Average Reward \t\t= -2.118\n",
      "Violation Counter \t= 133\n",
      "\n",
      "Iteration 18:  WAKKANAI, 2000 \n",
      "EPSILON = 0.89\n",
      "Average Reward \t\t= -1.485\n",
      "Violation Counter \t= 111\n",
      "\n",
      "Iteration 19:  WAKKANAI, 2002 \n",
      "EPSILON = 0.9\n",
      "Average Reward \t\t= -1.808\n",
      "Violation Counter \t= 133\n",
      "\n",
      "Iteration 20:  TOKYO, 2006 \n",
      "EPSILON = 0.9\n",
      "Average Reward \t\t= 0.652\n",
      "Violation Counter \t= 29\n",
      "\n",
      "Iteration 21:  WAKKANAI, 2008 \n",
      "EPSILON = 0.9\n",
      "Average Reward \t\t= -1.338\n",
      "Violation Counter \t= 101\n",
      "\n",
      "Iteration 22:  MINAMIDAITO, 2006 \n",
      "EPSILON = 0.91\n",
      "Average Reward \t\t= 0.476\n",
      "Violation Counter \t= 87\n",
      "\n",
      "Iteration 23:  TOKYO, 2000 \n",
      "EPSILON = 0.91\n",
      "Average Reward \t\t= 0.732\n",
      "Violation Counter \t= 39\n",
      "\n",
      "Iteration 24:  WAKKANAI, 2008 \n",
      "EPSILON = 0.91\n",
      "Average Reward \t\t= -1.120\n",
      "Violation Counter \t= 109\n",
      "\n",
      "Iteration 25:  WAKKANAI, 2009 \n",
      "EPSILON = 0.92\n",
      "Average Reward \t\t= -0.867\n",
      "Violation Counter \t= 90\n",
      "\n",
      "Iteration 26:  MINAMIDAITO, 2003 \n",
      "EPSILON = 0.92\n",
      "Average Reward \t\t= 0.712\n",
      "Violation Counter \t= 67\n",
      "\n",
      "Iteration 27:  WAKKANAI, 2009 \n",
      "EPSILON = 0.92\n",
      "Average Reward \t\t= -0.484\n",
      "Violation Counter \t= 75\n",
      "\n",
      "Iteration 28:  TOKYO, 2004 \n",
      "EPSILON = 0.92\n",
      "Average Reward \t\t= 1.423\n",
      "Violation Counter \t= 14\n",
      "\n",
      "Iteration 29:  MINAMIDAITO, 2001 \n",
      "EPSILON = 0.93\n",
      "Average Reward \t\t= 1.651\n",
      "Violation Counter \t= 3\n",
      "\n",
      "Iteration 30:  MINAMIDAITO, 2005 \n",
      "EPSILON = 0.93\n",
      "Average Reward \t\t= 1.387\n",
      "Violation Counter \t= 5\n",
      "\n",
      "Iteration 31:  TOKYO, 2008 \n",
      "EPSILON = 0.93\n",
      "Average Reward \t\t= 1.382\n",
      "Violation Counter \t= 0\n",
      "\n",
      "Iteration 32:  WAKKANAI, 2003 \n",
      "EPSILON = 0.93\n",
      "Average Reward \t\t= -0.176\n",
      "Violation Counter \t= 52\n",
      "\n",
      "Iteration 33:  TOKYO, 2006 \n",
      "EPSILON = 0.93\n",
      "Average Reward \t\t= 1.606\n",
      "Violation Counter \t= 7\n",
      "\n",
      "Iteration 34:  MINAMIDAITO, 2003 \n",
      "EPSILON = 0.94\n",
      "Average Reward \t\t= 0.962\n",
      "Violation Counter \t= 37\n",
      "\n",
      "Iteration 35:  TOKYO, 2009 \n",
      "EPSILON = 0.94\n",
      "Average Reward \t\t= 1.466\n",
      "Violation Counter \t= 11\n",
      "\n",
      "Iteration 36:  WAKKANAI, 2008 \n",
      "EPSILON = 0.94\n",
      "Average Reward \t\t= -0.431\n",
      "Violation Counter \t= 78\n",
      "\n",
      "Iteration 37:  MINAMIDAITO, 2000 \n",
      "EPSILON = 0.94\n",
      "Average Reward \t\t= 0.776\n",
      "Violation Counter \t= 57\n",
      "\n",
      "Iteration 38:  MINAMIDAITO, 2002 \n",
      "EPSILON = 0.94\n",
      "Average Reward \t\t= 0.919\n",
      "Violation Counter \t= 74\n",
      "\n",
      "Iteration 39:  TOKYO, 2005 \n",
      "EPSILON = 0.94\n",
      "Average Reward \t\t= 1.636\n",
      "Violation Counter \t= 11\n",
      "\n",
      "Iteration 40:  MINAMIDAITO, 2008 \n",
      "EPSILON = 0.94\n",
      "Average Reward \t\t= 1.270\n",
      "Violation Counter \t= 19\n",
      "\n",
      "Iteration 41:  TOKYO, 2008 \n",
      "EPSILON = 0.95\n",
      "Average Reward \t\t= 1.611\n",
      "Violation Counter \t= 6\n",
      "\n",
      "Iteration 42:  MINAMIDAITO, 2000 \n",
      "EPSILON = 0.95\n",
      "Average Reward \t\t= 0.989\n",
      "Violation Counter \t= 35\n",
      "\n",
      "Iteration 43:  WAKKANAI, 2003 \n",
      "EPSILON = 0.95\n",
      "Average Reward \t\t= -0.943\n",
      "Violation Counter \t= 84\n",
      "\n",
      "Iteration 44:  WAKKANAI, 2003 \n",
      "EPSILON = 0.95\n",
      "Average Reward \t\t= -0.312\n",
      "Violation Counter \t= 58\n",
      "\n",
      "Iteration 45:  WAKKANAI, 2006 \n",
      "EPSILON = 0.95\n",
      "Average Reward \t\t= -0.183\n",
      "Violation Counter \t= 58\n",
      "\n",
      "Iteration 46:  WAKKANAI, 2008 \n",
      "EPSILON = 0.95\n",
      "Average Reward \t\t= 0.003\n",
      "Violation Counter \t= 60\n",
      "\n",
      "Iteration 47:  TOKYO, 2007 \n",
      "EPSILON = 0.95\n",
      "Average Reward \t\t= 1.841\n",
      "Violation Counter \t= 4\n",
      "\n",
      "Iteration 48:  TOKYO, 2003 \n",
      "EPSILON = 0.95\n",
      "Average Reward \t\t= 1.805\n",
      "Violation Counter \t= 6\n",
      "\n",
      "Iteration 49:  MINAMIDAITO, 2000 \n",
      "EPSILON = 0.95\n",
      "Average Reward \t\t= 1.756\n",
      "Violation Counter \t= 3\n",
      "\n",
      "Iteration 50:  TOKYO, 2003 \n",
      "EPSILON = 0.95\n",
      "Average Reward \t\t= 1.700\n",
      "Violation Counter \t= 8\n",
      "\n",
      "Iteration 51:  WAKKANAI, 2007 \n",
      "EPSILON = 0.96\n",
      "Average Reward \t\t= 0.134\n",
      "Violation Counter \t= 49\n",
      "\n",
      "Iteration 52:  TOKYO, 2004 \n",
      "EPSILON = 0.96\n",
      "Average Reward \t\t= 1.589\n",
      "Violation Counter \t= 8\n",
      "\n",
      "Iteration 53:  WAKKANAI, 2000 \n",
      "EPSILON = 0.96\n",
      "Average Reward \t\t= -0.121\n",
      "Violation Counter \t= 65\n",
      "\n",
      "Iteration 54:  WAKKANAI, 2009 \n",
      "EPSILON = 0.96\n",
      "Average Reward \t\t= -0.105\n",
      "Violation Counter \t= 61\n",
      "\n",
      "Iteration 55:  MINAMIDAITO, 2009 \n",
      "EPSILON = 0.96\n",
      "Average Reward \t\t= 1.918\n",
      "Violation Counter \t= 3\n",
      "\n",
      "Iteration 56:  WAKKANAI, 2002 \n",
      "EPSILON = 0.96\n",
      "Average Reward \t\t= -0.141\n",
      "Violation Counter \t= 63\n",
      "\n",
      "Iteration 57:  MINAMIDAITO, 2009 \n",
      "EPSILON = 0.96\n",
      "Average Reward \t\t= 2.060\n",
      "Violation Counter \t= 5\n",
      "\n",
      "Iteration 58:  TOKYO, 2005 \n",
      "EPSILON = 0.96\n",
      "Average Reward \t\t= 1.938\n",
      "Violation Counter \t= 2\n",
      "\n",
      "Iteration 59:  TOKYO, 2001 \n",
      "EPSILON = 0.96\n",
      "Average Reward \t\t= 2.184\n",
      "Violation Counter \t= 0\n",
      "\n",
      "Iteration 60:  TOKYO, 2007 \n",
      "EPSILON = 0.96\n",
      "Average Reward \t\t= 1.995\n",
      "Violation Counter \t= 2\n",
      "\n",
      "Iteration 61:  TOKYO, 2006 \n",
      "EPSILON = 0.96\n",
      "Average Reward \t\t= 1.795\n",
      "Violation Counter \t= 7\n",
      "\n",
      "Iteration 62:  MINAMIDAITO, 2001 \n",
      "EPSILON = 0.96\n",
      "Average Reward \t\t= 2.306\n",
      "Violation Counter \t= 0\n",
      "\n",
      "Iteration 63:  WAKKANAI, 2007 \n",
      "EPSILON = 0.96\n",
      "Average Reward \t\t= 0.020\n",
      "Violation Counter \t= 60\n",
      "\n",
      "Iteration 64:  TOKYO, 2006 \n",
      "EPSILON = 0.96\n",
      "Average Reward \t\t= 1.963\n",
      "Violation Counter \t= 1\n",
      "\n",
      "Iteration 65:  MINAMIDAITO, 2005 \n",
      "EPSILON = 0.96\n",
      "Average Reward \t\t= 2.043\n",
      "Violation Counter \t= 4\n",
      "\n",
      "Iteration 66:  WAKKANAI, 2005 \n",
      "EPSILON = 0.96\n",
      "Average Reward \t\t= 0.025\n",
      "Violation Counter \t= 64\n",
      "\n",
      "Iteration 67:  WAKKANAI, 2003 \n",
      "EPSILON = 0.97\n",
      "Average Reward \t\t= 0.700\n",
      "Violation Counter \t= 38\n",
      "\n",
      "Iteration 68:  MINAMIDAITO, 2002 \n",
      "EPSILON = 0.97\n",
      "Average Reward \t\t= 2.332\n",
      "Violation Counter \t= 0\n",
      "\n",
      "Iteration 69:  TOKYO, 2005 \n",
      "EPSILON = 0.97\n",
      "Average Reward \t\t= 2.156\n",
      "Violation Counter \t= 3\n",
      "\n",
      "Iteration 70:  MINAMIDAITO, 2004 \n",
      "EPSILON = 0.97\n",
      "Average Reward \t\t= 2.061\n",
      "Violation Counter \t= 12\n",
      "\n",
      "Iteration 71:  WAKKANAI, 2007 \n",
      "EPSILON = 0.97\n",
      "Average Reward \t\t= 0.288\n",
      "Violation Counter \t= 58\n",
      "\n",
      "Iteration 72:  MINAMIDAITO, 2006 \n",
      "EPSILON = 0.97\n",
      "Average Reward \t\t= 1.454\n",
      "Violation Counter \t= 37\n",
      "\n",
      "Iteration 73:  TOKYO, 2002 \n",
      "EPSILON = 0.97\n",
      "Average Reward \t\t= 1.683\n",
      "Violation Counter \t= 4\n",
      "\n",
      "Iteration 74:  TOKYO, 2003 \n",
      "EPSILON = 0.97\n",
      "Average Reward \t\t= 1.808\n",
      "Violation Counter \t= 4\n",
      "\n",
      "Iteration 75:  TOKYO, 2007 \n",
      "EPSILON = 0.97\n",
      "Average Reward \t\t= 1.776\n",
      "Violation Counter \t= 1\n",
      "\n",
      "Iteration 76:  TOKYO, 2007 \n",
      "EPSILON = 0.97\n",
      "Average Reward \t\t= 1.803\n",
      "Violation Counter \t= 0\n",
      "\n",
      "Iteration 77:  WAKKANAI, 2006 \n",
      "EPSILON = 0.97\n",
      "Average Reward \t\t= 0.087\n",
      "Violation Counter \t= 56\n",
      "\n",
      "Iteration 78:  MINAMIDAITO, 2000 \n",
      "EPSILON = 0.97\n",
      "Average Reward \t\t= 1.914\n",
      "Violation Counter \t= 1\n",
      "\n",
      "Iteration 79:  MINAMIDAITO, 2004 \n",
      "EPSILON = 0.97\n",
      "Average Reward \t\t= 1.930\n",
      "Violation Counter \t= 0\n"
     ]
    }
   ],
   "source": [
    "#TRAIN \n",
    "dqn = DQN()\n",
    "# for recording weights\n",
    "oldfc1 = dqn.eval_net.fc1.weight.data.cpu().numpy().flatten()\n",
    "old2fc1 = oldfc1\n",
    "\n",
    "oldfc2 = dqn.eval_net.fc2.weight.data.cpu().numpy().flatten()\n",
    "old2fc2 = oldfc2\n",
    "\n",
    "# oldfc3 = dqn.eval_net.fc3.weight.data.cpu().numpy().flatten()\n",
    "# old2fc3 = oldfc3\n",
    "\n",
    "oldout = dqn.eval_net.out.weight.data.cpu().numpy().flatten()\n",
    "old2out = oldout\n",
    "########################################\n",
    "\n",
    "best_iteration = -1\n",
    "best_avg_reward = -1000 #initialize best average reward to very low value\n",
    "reset_counter = 0 #count number of times the battery had to be reset\n",
    "change_hr = 0\n",
    "# PFILENAME = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(8)) #create random filename\n",
    "# BFILENAME = \"best\"+PFILENAME + \".pt\" #this file stores the best model\n",
    "# TFILENAME = \"terminal\"+PFILENAME + \".pt\" #this file stores the last model\n",
    "\n",
    "avg_reward_rec = [] #record the yearly average rewards over the entire duration of training\n",
    "violation_rec = []\n",
    "print('\\nTRAINING IN PROGRESS\\n')\n",
    "print('Device: ', dqn.device)\n",
    "\n",
    "for iteration in range(NO_OF_ITERATIONS):\n",
    "#     A = 2\n",
    "#     B = 4\n",
    "#     if(10<iteration<=30):\n",
    "#         counter = iteration%10\n",
    "#         EPSILON = 0.5*counter/(counter+A)+0.5 #sawtooth epsilon scheduling\n",
    "#     elif(iteration>30):\n",
    "#         EPSILON = 0.5*(iteration-30)/(iteration-30+B)+0.5 #asymptotic increase to 0.96\n",
    "#     else:\n",
    "#         EPSILON = 0.9\n",
    "\n",
    "    EPSILON = 0.5*(iteration)/(iteration+5)+0.5\n",
    "    \n",
    "    LOCATION = random.choice(['tokyo','wakkanai','minamidaito'])\n",
    "    YEAR = random.choice(np.arange(2000,2010))\n",
    "    capm = CAPM(LOCATION,YEAR,shuffle=False, trainmode=False) #instantiate the CAPM class\n",
    "    capm.eno = ENO(LOCATION,YEAR, shuffle=False, day_balance=False) #instantiate the environment inside the CAPM class\n",
    "    capm.HMAX = capm.eno.SMAX #maximum power output of solar cell is set in CAPM object using the value in ENO object\n",
    "#     clear_output()\n",
    "    print('\\nIteration {}:  {}, {} '.format(iteration, LOCATION.upper(), YEAR))\n",
    "    print('EPSILON = {:.2}'.format(EPSILON))\n",
    "\n",
    "    s, r, day_end, year_end = capm.reset()\n",
    "    yr_record = np.empty(4)\n",
    "\n",
    "    record = np.empty(4) #record for battery, henergy, reward and action\n",
    "    transition_rec = np.zeros((capm.eno.TIME_STEPS, N_STATES * 2 + 2)) #record all the transition in one day\n",
    "\n",
    "    while True:\n",
    "        a = dqn.choose_action(stdize(s))\n",
    "\n",
    "        # present state = [batt, enp, henergy]\n",
    "        record = np.vstack((record, [s[0],s[2],r, a])) # record battery, henergy, reward and action for troubleshooting\n",
    "        yr_record = np.vstack((yr_record, [s[0],s[2],r, a]))\n",
    "\n",
    "        # take action\n",
    "        s_, r, day_end, year_end = capm.step(a)\n",
    "        \n",
    "        temp_transitions = np.hstack((stdize(s), [a, r], stdize(s_)))\n",
    "        transition_rec[capm.eno.hr-1,:] = temp_transitions\n",
    "\n",
    "        if (day_end):\n",
    "            transition_rec[:,5] += r #broadcast reward to all states\n",
    "            decay_factor = [i for i in (LAMBDA**n for n in reversed(range(0, capm.eno.TIME_STEPS)))]\n",
    "            transition_rec[:,5] = transition_rec[:,5] * decay_factor #decay reward proportionately\n",
    "            dqn.store_day_transition(transition_rec)\n",
    "\n",
    "        if dqn.memory_counter > MEMORY_CAPACITY:\n",
    "            dqn.learn()\n",
    "\n",
    "        if dqn.nettoggle:\n",
    "            change_hr = capm.eno.day*24+capm.eno.hr #to mark when the DQN is updated.\n",
    "            dqn.nettoggle = not dqn.nettoggle\n",
    "\n",
    "        if (year_end):\n",
    "            break\n",
    "\n",
    "        # transition to new state\n",
    "        s = s_\n",
    "\n",
    "    record = np.delete(record, 0, 0) #remove the first row which is garbage\n",
    "    reward_rec = record[:,2] #extract reward information from the record array\n",
    "    reward_rec = reward_rec[::24] #only consider terminal rewards\n",
    "    print(\"Average Reward \\t\\t= {:.3f}\".format(np.mean(reward_rec)))\n",
    "    print(\"Violation Counter \\t= {}\".format(capm.violation_counter))\n",
    "    \n",
    "    # Log the average reward in avg_reward_rec\n",
    "    avg_reward_rec = np.append(avg_reward_rec, np.mean(reward_rec))\n",
    "    violation_rec = np.append(violation_rec, capm.violation_counter)\n",
    "\n",
    "#     if(best_avg_reward < np.mean(reward_rec)):\n",
    "#         best_avg_reward = np.mean(reward_rec)\n",
    "    \n",
    "#     if(best_avg_reward > 1.5 or iteration > 20):\n",
    "#         EPSILON = 0.9\n",
    "#         LR = 0.01\n",
    "        \n",
    "#     if (capm.violation_counter < 5):\n",
    "#         reset_flag = False\n",
    "#         EPSILON = 0.95\n",
    "#         LR = 0.001\n",
    "        \n",
    "\n",
    "#     # Check if reward beats the High Score and possible save it    \n",
    "#     if (iteration > 19): #save the best models only after 20 iterations\n",
    "#         print(\"Best Score \\t = {:8.3f} @ Iteration No. {}\".format(best_avg_reward, best_iteration))\n",
    "#         if(best_avg_reward < np.mean(reward_rec)):\n",
    "#             best_iteration = iteration\n",
    "#             best_avg_reward = np.mean(reward_rec)\n",
    "#             print(\"Saving Model\")\n",
    "#             torch.save(dqn.eval_net.state_dict(), BFILENAME)\n",
    "#     else:\n",
    "#         print(\"\\r\")\n",
    "\n",
    "   \n",
    "    \n",
    "###########################################################################################\n",
    "#   PLOT battery levels, hourly rewards and the weights\n",
    "    yr_record = np.delete(yr_record, 0, 0) #remove the first row which is garbage\n",
    "#     NO_OF_DAYS = capm.eno.NO_OF_DAYS\n",
    "    hourly_yr_reward_rec = yr_record[:,2]\n",
    "    yr_reward_rec = hourly_yr_reward_rec[::24]\n",
    "\n",
    "    \n",
    "#     fig = plt.figure(figsize=(24,3))\n",
    "#     TIME_STEPS = capm.eno.TIME_STEPS\n",
    "#     NO_OF_DAYS = capm.eno.NO_OF_DAYS\n",
    "#     DAY_SPACING = 15\n",
    "#     TICK_SPACING = TIME_STEPS*DAY_SPACING\n",
    "#     #plot battery\n",
    "#     ax = fig.add_subplot(111)\n",
    "#     ax.plot(np.arange(0,TIME_STEPS*NO_OF_DAYS),yr_record[:,0],'r',alpha=0.7)\n",
    "#     ax.set_ylim([0,1])\n",
    "#     ax.axvline(x=change_hr)\n",
    "#     ax.xaxis.set_major_locator(ticker.MultipleLocator(TICK_SPACING))\n",
    "# #     labels = [item for item in ax.get_xticklabels()]\n",
    "# #     print(labels)\n",
    "# #     labels [15:-1] = np.arange(0,NO_OF_DAYS,DAY_SPACING) #the first label is reserved to negative values\n",
    "# #     ax.set_xticklabels(labels)\n",
    "#     #plot hourly reward\n",
    "#     ax0 = ax.twinx()\n",
    "#     ax0.plot(hourly_yr_reward_rec, color='m',alpha=0.4)\n",
    "#     ax0.set_ylim(-10,10)\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "#     fig = plt.figure(figsize=(18,3))\n",
    "#     ax1 = fig.add_subplot(131)\n",
    "#     newfc1 = dqn.eval_net.fc1.weight.data.cpu().numpy().flatten()\n",
    "#     ax1.plot(old2fc1,color='b', alpha=0.4)\n",
    "#     ax1.plot(oldfc1,color='b',alpha = 0.7)\n",
    "#     ax1.plot(newfc1,color='b')\n",
    "#     old2fc1 = oldfc1\n",
    "#     oldfc1 = newfc1\n",
    "    \n",
    "#     ax2 = fig.add_subplot(132)\n",
    "#     newfc2 = dqn.eval_net.fc2.weight.data.cpu().numpy().flatten()\n",
    "#     ax2.plot(old2fc2,color='y', alpha=0.4)\n",
    "#     ax2.plot(oldfc2,color='y',alpha = 0.7)\n",
    "#     ax2.plot(newfc2,color='y')\n",
    "#     old2fc2 = oldfc2\n",
    "#     oldfc2 = newfc2\n",
    "    \n",
    "# #     ax3 = fig.add_subplot(143)\n",
    "# #     newfc3 = dqn.eval_net.fc3.weight.data.cpu().numpy().flatten()\n",
    "# #     ax3.plot(old2fc3,color='y', alpha=0.4)\n",
    "# #     ax3.plot(oldfc3,color='y',alpha = 0.7)\n",
    "# #     ax3.plot(newfc3,color='y')\n",
    "# #     old2fc3 = oldfc3\n",
    "# #     oldfc3 = newfc3\n",
    "    \n",
    "#     axO = fig.add_subplot(133)\n",
    "#     newout = dqn.eval_net.out.weight.data.cpu().numpy().flatten()\n",
    "#     axO.plot(old2out,color='g', alpha=0.4)\n",
    "#     axO.plot(oldout,color='g',alpha=0.7)\n",
    "#     axO.plot(newout,color='g')\n",
    "#     old2out = oldout\n",
    "#     oldout = newout\n",
    "    \n",
    "#     fig.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "    # End of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPSILON =  0.97\n",
      "LR      =  1e-05\n",
      "\n",
      "LAST PHASE ITERATION #0:  TOKYO, 2006 \n",
      "Average Reward \t\t= 1.706\n",
      "Violation Counter \t= 5\n",
      "***MEASURING PERFORMANCE OF THE MODEL***\n",
      "\tBEST AVERAGE ANNUAL AVERAGE REWARD = -1000.000\n",
      "\tBEST TOTAL VIOLATIONS              = 1000\n",
      "\n",
      "\tAverage Annual Average Reward      = 1.992\n",
      "\tTotal Violations                   = 1.0\n",
      "****************************************\n",
      "\n",
      "LAST PHASE ITERATION #1:  TOKYO, 2000 \n",
      "Average Reward \t\t= 1.723\n",
      "Violation Counter \t= 4\n",
      "***MEASURING PERFORMANCE OF THE MODEL***\n",
      "\tBEST AVERAGE ANNUAL AVERAGE REWARD = 1.992\n",
      "\tBEST TOTAL VIOLATIONS              = 1.0\n",
      "\n",
      "\tAverage Annual Average Reward      = 1.887\n",
      "\tTotal Violations                   = 2.0\n",
      "****************************************\n",
      "\n",
      "LAST PHASE ITERATION #2:  WAKKANAI, 2006 \n",
      "Average Reward \t\t= 0.072\n",
      "Violation Counter \t= 59\n",
      "***MEASURING PERFORMANCE OF THE MODEL***\n",
      "\tBEST AVERAGE ANNUAL AVERAGE REWARD = 1.992\n",
      "\tBEST TOTAL VIOLATIONS              = 1.0\n",
      "\n",
      "\tAverage Annual Average Reward      = 2.098\n",
      "\tTotal Violations                   = 4.0\n",
      "****************************************\n",
      "\n",
      "LAST PHASE ITERATION #3:  MINAMIDAITO, 2007 \n",
      "Average Reward \t\t= 1.784\n",
      "Violation Counter \t= 15\n",
      "***MEASURING PERFORMANCE OF THE MODEL***\n",
      "\tBEST AVERAGE ANNUAL AVERAGE REWARD = 2.098\n",
      "\tBEST TOTAL VIOLATIONS              = 1.0\n",
      "\n",
      "\tAverage Annual Average Reward      = 1.961\n",
      "\tTotal Violations                   = 4.0\n",
      "****************************************\n",
      "\n",
      "LAST PHASE ITERATION #4:  TOKYO, 2007 \n",
      "Average Reward \t\t= 1.794\n",
      "Violation Counter \t= 4\n",
      "***MEASURING PERFORMANCE OF THE MODEL***\n",
      "\tBEST AVERAGE ANNUAL AVERAGE REWARD = 2.098\n",
      "\tBEST TOTAL VIOLATIONS              = 1.0\n",
      "\n",
      "\tAverage Annual Average Reward      = 1.926\n",
      "\tTotal Violations                   = 2.0\n",
      "****************************************\n",
      "\n",
      "LAST PHASE ITERATION #5:  TOKYO, 2004 \n",
      "Average Reward \t\t= 1.734\n",
      "Violation Counter \t= 8\n",
      "***MEASURING PERFORMANCE OF THE MODEL***\n",
      "\tBEST AVERAGE ANNUAL AVERAGE REWARD = 2.098\n",
      "\tBEST TOTAL VIOLATIONS              = 1.0\n",
      "\n",
      "\tAverage Annual Average Reward      = 2.070\n",
      "\tTotal Violations                   = 2.0\n",
      "****************************************\n",
      "\n",
      "LAST PHASE ITERATION #6:  MINAMIDAITO, 2002 \n",
      "Average Reward \t\t= 1.938\n",
      "Violation Counter \t= 1\n",
      "***MEASURING PERFORMANCE OF THE MODEL***\n",
      "\tBEST AVERAGE ANNUAL AVERAGE REWARD = 2.098\n",
      "\tBEST TOTAL VIOLATIONS              = 1.0\n",
      "\n",
      "\tAverage Annual Average Reward      = 1.404\n",
      "\tTotal Violations                   = 1.0\n",
      "****************************************\n",
      "\n",
      "LAST PHASE ITERATION #7:  WAKKANAI, 2006 \n",
      "Average Reward \t\t= 0.147\n",
      "Violation Counter \t= 52\n",
      "***MEASURING PERFORMANCE OF THE MODEL***\n",
      "\tBEST AVERAGE ANNUAL AVERAGE REWARD = 2.098\n",
      "\tBEST TOTAL VIOLATIONS              = 1.0\n",
      "\n",
      "\tAverage Annual Average Reward      = 1.848\n",
      "\tTotal Violations                   = 1.0\n",
      "****************************************\n",
      "\n",
      "LAST PHASE ITERATION #8:  MINAMIDAITO, 2005 \n",
      "Average Reward \t\t= 1.800\n",
      "Violation Counter \t= 4\n",
      "***MEASURING PERFORMANCE OF THE MODEL***\n",
      "\tBEST AVERAGE ANNUAL AVERAGE REWARD = 2.098\n",
      "\tBEST TOTAL VIOLATIONS              = 1.0\n",
      "\n",
      "\tAverage Annual Average Reward      = 1.865\n",
      "\tTotal Violations                   = 2.0\n",
      "****************************************\n",
      "\n",
      "LAST PHASE ITERATION #9:  WAKKANAI, 2004 \n",
      "Average Reward \t\t= 0.227\n",
      "Violation Counter \t= 47\n",
      "***MEASURING PERFORMANCE OF THE MODEL***\n",
      "\tBEST AVERAGE ANNUAL AVERAGE REWARD = 2.098\n",
      "\tBEST TOTAL VIOLATIONS              = 1.0\n",
      "\n",
      "\tAverage Annual Average Reward      = 1.781\n",
      "\tTotal Violations                   = 1.0\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "#END OF TRAINING PHASE - CHOOSING THE BEST MODEL INSTANCE\n",
    "#INCREASE GREEDY RATE\n",
    "#VALIDATE AFTER EVERY ITERATION\n",
    "\n",
    "# Use this model and its output as base standards for the last phase of training\n",
    "best_avg_avg_reward = -1000\n",
    "best_net_avg_reward = dqn.eval_net\n",
    "best_avg_v_counter = 1000\n",
    "best_net_v_counter = dqn.eval_net\n",
    "\n",
    "\n",
    "NO_OF_LAST_PHASE_ITERATIONS = 10\n",
    "EPSILON = 0.97\n",
    "print(\"EPSILON = \", EPSILON)\n",
    "print(\"LR      = \", LR)\n",
    "\n",
    "for iteration in range(NO_OF_LAST_PHASE_ITERATIONS):\n",
    "    LOCATION = random.choice(['tokyo','wakkanai','minamidaito'])\n",
    "    YEAR = random.choice(np.arange(2000,2010))\n",
    "    capm = CAPM(LOCATION,YEAR,shuffle=False, trainmode=False) #instantiate the CAPM class\n",
    "    capm.eno = ENO(LOCATION,YEAR, shuffle=False, day_balance=False) #instantiate the environment inside the CAPM class\n",
    "    capm.HMAX = capm.eno.SMAX #maximum power output of solar cell is set in CAPM object using the value in ENO object\n",
    "\n",
    "    print('\\nLAST PHASE ITERATION #{}:  {}, {} '.format(iteration, LOCATION.upper(), YEAR))\n",
    "    \n",
    "    \n",
    "    my_avg_reward = -1000\n",
    "    my_v_counter = 1000\n",
    "    \n",
    "    s, r, day_end, year_end = capm.reset()\n",
    "    yr_record = np.empty(4)\n",
    "\n",
    "    record = np.empty(4) #record for battery, henergy, reward and action\n",
    "    transition_rec = np.zeros((capm.eno.TIME_STEPS, N_STATES * 2 + 2)) #record all the transition in one day\n",
    "\n",
    "    while True:\n",
    "        a = dqn.choose_action(stdize(s))\n",
    "\n",
    "        # present state = [batt, enp, henergy]\n",
    "        record = np.vstack((record, [s[0],s[2],r, a])) # record battery, henergy, reward and action for troubleshooting\n",
    "        yr_record = np.vstack((yr_record, [s[0],s[2],r, a]))\n",
    "\n",
    "        # take action\n",
    "        s_, r, day_end, year_end = capm.step(a)\n",
    "        \n",
    "        temp_transitions = np.hstack((stdize(s), [a, r], stdize(s_)))\n",
    "        transition_rec[capm.eno.hr-1,:] = temp_transitions\n",
    "\n",
    "        if (day_end):\n",
    "            transition_rec[:,5] += r #broadcast reward to all states\n",
    "            decay_factor = [i for i in (LAMBDA**n for n in reversed(range(0, capm.eno.TIME_STEPS)))]\n",
    "            transition_rec[:,5] = transition_rec[:,5] * decay_factor #decay reward proportionately\n",
    "            dqn.store_day_transition(transition_rec)\n",
    "\n",
    "        if dqn.memory_counter > MEMORY_CAPACITY:\n",
    "            dqn.learn()\n",
    "\n",
    "        if dqn.nettoggle:\n",
    "            change_hr = capm.eno.day*24+capm.eno.hr #to mark when the DQN is updated.\n",
    "            dqn.nettoggle = not dqn.nettoggle\n",
    "\n",
    "        if (year_end):\n",
    "            break\n",
    "\n",
    "        # transition to new state\n",
    "        s = s_\n",
    "\n",
    "    record = np.delete(record, 0, 0) #remove the first row which is garbage\n",
    "    reward_rec = record[:,2] #extract reward information from the record array\n",
    "    reward_rec = reward_rec[::24] #only consider terminal rewards\n",
    "    print(\"Average Reward \\t\\t= {:.3f}\".format(np.mean(reward_rec)))\n",
    "    print(\"Violation Counter \\t= {}\".format(capm.violation_counter))\n",
    "    \n",
    "     # Log the average reward in avg_reward_rec\n",
    "    avg_reward_rec = np.append(avg_reward_rec, np.mean(reward_rec))\n",
    "    violation_rec = np.append(violation_rec, capm.violation_counter)\n",
    "    \n",
    "    print(\"***MEASURING PERFORMANCE OF THE MODEL***\")\n",
    "    print(\"\\tBEST AVERAGE ANNUAL AVERAGE REWARD = {:.3f}\".format(best_avg_avg_reward))\n",
    "    print(\"\\tBEST TOTAL VIOLATIONS              = {}\".format(best_avg_v_counter))\n",
    "    LOCATION = 'tokyo'\n",
    "    results = np.empty(3)\n",
    "    for YEAR in np.arange(2010,2015):\n",
    "        capm = CAPM(LOCATION,YEAR,shuffle=False, trainmode=False) #instantiate the CAPM class\n",
    "        capm.eno = ENO(LOCATION,YEAR, shuffle=False, day_balance=False) #instantiate the environment inside the CAPM class\n",
    "        capm.HMAX = capm.eno.SMAX #maximum power output of solar cell is set in CAPM object using the value in ENO object\n",
    "\n",
    "        s, r, day_end, year_end = capm.reset()\n",
    "        yr_test_record = np.empty(4)\n",
    "\n",
    "        while True:\n",
    "            a = dqn.choose_greedy_action(stdize(s))\n",
    "            #state = [batt, enp, henergy, fcast]\n",
    "            yr_test_record = np.vstack((yr_test_record, [s[0],s[2],r, a])) #record battery, henergy, reward and action\n",
    "            # take action\n",
    "            s_, r, day_end, year_end = capm.step(a)\n",
    "            if year_end:\n",
    "                break\n",
    "            s = s_\n",
    "\n",
    "        yr_test_record = np.delete(yr_test_record, 0, 0) #remove the first row which is garbage\n",
    "        yr_test_reward_rec = yr_test_record[:,2]\n",
    "        yr_test_reward_rec = yr_test_reward_rec[::24] #annual average reward\n",
    "        results = np.vstack((results, [int(YEAR), np.mean(yr_test_reward_rec), int(capm.violation_counter)]))\n",
    "    results = np.delete(results,0,0)\n",
    "    my_avg_reward = np.mean(results[:,1]) #the average of annual average rewards\n",
    "    my_v_counter = np.sum(results[:,-1]) #total sum of violations\n",
    "    print(\"\\n\\tAverage Annual Average Reward      = {:.3f}\".format(my_avg_reward))\n",
    "    print(\"\\tTotal Violations                   = {}\".format(my_v_counter))\n",
    "\n",
    "    if (my_avg_reward > best_avg_avg_reward):\n",
    "            best_avg_avg_reward = my_avg_reward\n",
    "            best_net_avg_reward = dqn.eval_net\n",
    "\n",
    "    if (my_v_counter < best_avg_v_counter):\n",
    "        best_avg_v_counter = my_v_counter\n",
    "        best_net_v_counter = dqn.eval_net\n",
    "    elif (my_v_counter == best_avg_v_counter):\n",
    "        if (my_avg_reward > best_avg_avg_reward):\n",
    "            best_avg_v_counter = my_v_counterO\n",
    "            best_net_v_counter = dqn.eval_net\n",
    "    print(\"****************************************\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n",
      "Train time: 0:33:12.395995\n"
     ]
    }
   ],
   "source": [
    "print('Device: ', dqn.device)\n",
    "print('Train time: {}'.format(datetime.now() - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x216 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(9,3))\n",
    "# Plot the average reward log\n",
    "\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.set_ylabel(\"Reward\")\n",
    "# ax1.set_ylim([-3,3]);\n",
    "ax1.plot(avg_reward_rec,'b')\n",
    "ax1.tick_params(axis='y', colors='b')\n",
    "\n",
    "#Plot the violation record log\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel(\"Violations\",color = 'r')\n",
    "ax2.plot(violation_rec,'r')\n",
    "for xpt in np.argwhere(violation_rec<1):\n",
    "    ax2.axvline(x=xpt,color='g')\n",
    "ax2.set_ylim([0,50]);\n",
    "ax2.tick_params(axis='y', colors='r')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING BEST MODEL BASED ON AVERAGE REWARD METRIC\n",
    "dqn = DQN()\n",
    "dqn.eval_net = best_net_avg_reward\n",
    "LOCATION = 'tokyo'\n",
    "results = np.empty(3)\n",
    "for YEAR in np.arange(2000,2019):\n",
    "    capm = CAPM(LOCATION,YEAR,shuffle=False, trainmode=False) #instantiate the CAPM class\n",
    "    capm.eno = ENO(LOCATION,YEAR, shuffle=False, day_balance=False) #instantiate the environment inside the CAPM class\n",
    "    capm.HMAX = capm.eno.SMAX #maximum power output of solar cell is set in CAPM object using the value in ENO object\n",
    "\n",
    "    s, r, day_end, year_end = capm.reset()\n",
    "    yr_test_record = np.empty(4)\n",
    "\n",
    "    while True:\n",
    "        a = dqn.choose_greedy_action(stdize(s))\n",
    "\n",
    "        #state = [batt, enp, henergy, fcast]\n",
    "        yr_test_record = np.vstack((yr_test_record, [s[0],s[2],r, a])) #record battery, henergy, reward and action\n",
    "\n",
    "        # take action\n",
    "        s_, r, day_end, year_end = capm.step(a)\n",
    "\n",
    "        if year_end:\n",
    "            break\n",
    "\n",
    "        s = s_\n",
    "\n",
    "    yr_test_record = np.delete(yr_test_record, 0, 0) #remove the first row which is garbage\n",
    "\n",
    "#     #Plot the reward and battery for the entire year run\n",
    "#     title = LOCATION.upper() + ',' + str(YEAR)\n",
    "\n",
    "#     NO_OF_DAYS = capm.eno.NO_OF_DAYS\n",
    "    yr_test_reward_rec = yr_test_record[:,2]\n",
    "    yr_test_reward_rec = yr_test_reward_rec[::24]\n",
    "#     print('Average Reward for',title, '=', np.mean(yr_test_reward_rec))\n",
    "#     print('Violations for',title, '=', capm.violation_counter)\n",
    "    \n",
    "    results = np.vstack((results, [int(YEAR), np.mean(yr_test_reward_rec), int(capm.violation_counter)]))\n",
    "\n",
    "#     fig = plt.figure(figsize=(24,3))\n",
    "#     fig.suptitle(title, fontsize=15)\n",
    "\n",
    "#     #     ax1 = fig.add_subplot(211)\n",
    "#     #     ax1.plot(yr_test_reward_rec)\n",
    "#     #     ax1.set_title(\"\\n\\nYear Run Reward\")\n",
    "#     #     ax1.set_ylim([-3,1])\n",
    "\n",
    "#     ax2 = fig.add_subplot(111)\n",
    "#     ax2.plot(yr_test_record[:,0],'r')\n",
    "#     ax2.set_title(\"\\n\\nYear Run Battery\")\n",
    "#     ax2.set_ylim([0,1])\n",
    "#     plt.sca(ax2)\n",
    "#     plt.xticks(np.arange(0, NO_OF_DAYS*24, 50*24),np.arange(0,NO_OF_DAYS,50))\n",
    "\n",
    "#     fig.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "results = np.delete(results,0,0)\n",
    "\n",
    "print(\"TESTING BEST MODEL BASED ON AVERAGE REWARD METRIC\")\n",
    "print('YEAR\\t\\tAVG_RWD\\t\\tVIOLATIONS')\n",
    "for x in np.arange(0,results.shape[0]):\n",
    "    print('{} \\t\\t {} \\t\\t {}'.format(int(results[x,0]), np.around(results[x,1],2), int(results[x,-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING BASED ON VIOLATION COUNTER METRIC\n",
    "dqn = DQN()\n",
    "dqn.eval_net = best_net_v_counter\n",
    "\n",
    "LOCATION = 'tokyo'\n",
    "results = np.empty(3)\n",
    "for YEAR in np.arange(2000,2019):\n",
    "    capm = CAPM(LOCATION,YEAR,shuffle=False, trainmode=False) #instantiate the CAPM class\n",
    "    capm.eno = ENO(LOCATION,YEAR, shuffle=False, day_balance=False) #instantiate the environment inside the CAPM class\n",
    "    capm.HMAX = capm.eno.SMAX #maximum power output of solar cell is set in CAPM object using the value in ENO object\n",
    "\n",
    "    s, r, day_end, year_end = capm.reset()\n",
    "    yr_test_record = np.empty(4)\n",
    "\n",
    "    while True:\n",
    "        a = dqn.choose_greedy_action(stdize(s))\n",
    "\n",
    "        #state = [batt, enp, henergy, fcast]\n",
    "        yr_test_record = np.vstack((yr_test_record, [s[0],s[2],r, a])) #record battery, henergy, reward and action\n",
    "\n",
    "        # take action\n",
    "        s_, r, day_end, year_end = capm.step(a)\n",
    "\n",
    "        if year_end:\n",
    "            break\n",
    "\n",
    "        s = s_\n",
    "\n",
    "    yr_test_record = np.delete(yr_test_record, 0, 0) #remove the first row which is garbage\n",
    "\n",
    "#     #Plot the reward and battery for the entire year run\n",
    "#     title = LOCATION.upper() + ',' + str(YEAR)\n",
    "\n",
    "#     NO_OF_DAYS = capm.eno.NO_OF_DAYS\n",
    "    yr_test_reward_rec = yr_test_record[:,2]\n",
    "    yr_test_reward_rec = yr_test_reward_rec[::24]\n",
    "#     print('Average Reward for',title, '=', np.mean(yr_test_reward_rec))\n",
    "#     print('Violations for',title, '=', capm.violation_counter)\n",
    "    \n",
    "    results = np.vstack((results, [int(YEAR), np.mean(yr_test_reward_rec), int(capm.violation_counter)]))\n",
    "\n",
    "#     fig = plt.figure(figsize=(24,3))\n",
    "#     fig.suptitle(title, fontsize=15)\n",
    "\n",
    "#     #     ax1 = fig.add_subplot(211)\n",
    "#     #     ax1.plot(yr_test_reward_rec)\n",
    "#     #     ax1.set_title(\"\\n\\nYear Run Reward\")\n",
    "#     #     ax1.set_ylim([-3,1])\n",
    "\n",
    "#     ax2 = fig.add_subplot(111)\n",
    "#     ax2.plot(yr_test_record[:,0],'r')\n",
    "#     ax2.set_title(\"\\n\\nYear Run Battery\")\n",
    "#     ax2.set_ylim([0,1])\n",
    "#     plt.sca(ax2)\n",
    "#     plt.xticks(np.arange(0, NO_OF_DAYS*24, 50*24),np.arange(0,NO_OF_DAYS,50))\n",
    "\n",
    "#     fig.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "results = np.delete(results,0,0)\n",
    "\n",
    "print(\"TESTING BASED ON VIOLATION COUNTER METRIC\")\n",
    "print('YEAR\\t\\tAVG_RWD\\t\\tVIOLATIONS')\n",
    "for x in np.arange(0,results.shape[0]):\n",
    "    print('{} \\t\\t {} \\t\\t {}'.format(int(results[x,0]), np.around(results[x,1],2), int(results[x,-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total runtime: {}'.format(datetime.now() - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.eval_net = best_net_avg_reward\n",
    "torch.save(dqn.eval_net.state_dict(), 'CB.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Plot the reward and battery for the entire year run on a day by day basis\n",
    "# title = LOCATION.upper() + ',' + str(YEAR)\n",
    "# TIME_AXIS = np.arange(0,capm.eno.TIME_STEPS)\n",
    "# for DAY in range(0,10):#capm.eno.NO_OF_DAYS):\n",
    "#     START = DAY*24\n",
    "#     END = START+24\n",
    "\n",
    "#     daytitle = title + ' - DAY ' + str(DAY)\n",
    "#     fig = plt.figure(figsize=(16,4))\n",
    "#     st = fig.suptitle(daytitle)\n",
    "\n",
    "#     ax2 = fig.add_subplot(121)\n",
    "#     ax2.plot(yr_test_record[START:END,1],'g')\n",
    "#     ax2.set_title(\"HARVESTED ENERGY\")\n",
    "#     plt.xlabel(\"Hour\")\n",
    "#     ax2.set_ylim([0,1])\n",
    "\n",
    "#     #plot battery for year run\n",
    "#     ax1 = fig.add_subplot(122)\n",
    "#     ax1.plot(TIME_AXIS,yr_test_record[START:END,0],'r') \n",
    "# #     ax1.plot(TIME_AXIS, np.ones(capm.eno.TIME_STEPS)*capm.BOPT/capm.BMAX,'r--')\n",
    "#     ax1.plot(TIME_AXIS, np.ones(capm.eno.TIME_STEPS)*capm.BOPT/capm.BMAX,'r--')\n",
    "#     ax1.text(0.1, 0.2, \"BINIT = %.2f\\n\" %(yr_test_record[START,0]),fontsize=11, ha='left')\n",
    "#     ax1.text(0.1, 0.4, \"TENP = %.2f\\n\" %(capm.BOPT/capm.BMAX-yr_test_record[END,0]),fontsize=11, ha='left')\n",
    "#     ax1.text(0.1, 0.3, \"BMEAN = %.2f\\n\" %(np.mean(yr_test_record[START:END,0])),fontsize=11, ha='left')\n",
    "\n",
    "\n",
    "\n",
    "#     ax1.set_title(\"YEAR RUN TEST\")\n",
    "#     if END < (capm.eno.NO_OF_DAYS*capm.eno.TIME_STEPS):\n",
    "#         ax1.text(0.1, 0, \"REWARD = %.2f\\n\" %(yr_test_record[END,2]),fontsize=13, ha='left')\n",
    "#     plt.xlabel(\"Hour\")\n",
    "#     ax1.set_ylabel('Battery', color='r',fontsize=12)\n",
    "#     ax1.set_ylim([0,1])\n",
    "\n",
    "#     #plot actions for year run\n",
    "#     ax1a = ax1.twinx()\n",
    "#     ax1a.plot(yr_test_record[START:END,3])\n",
    "#     ax1a.set_ylim([0,N_ACTIONS])\n",
    "#     ax1a.set_ylabel('Duty Cycle', color='b',fontsize=12)\n",
    "\n",
    "#     fig.tight_layout()\n",
    "#     st.set_y(0.95)\n",
    "#     fig.subplots_adjust(top=0.75)\n",
    "#     plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
